{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bc6a1a-123c-41f9-8ab2-72eb10f5c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hot-words from the ASR transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800e6ed6-918d-4718-9187-8c9af99f5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbaad662-c3f7-4bd2-921b-b6299bf6c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to read reference CSV file\n",
    "\n",
    "def read_ref_csv(path):\n",
    "    # Read a CSV file containing reference word sequences\n",
    "    ref = dict()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip().split(\",\")\n",
    "            if \".mp3\" in line[0]:\n",
    "                utt_name = line[0]\n",
    "                assert(utt_name not in ref)\n",
    "                ref[utt_name] = line[1].upper() # wav2vec2-large-960h only supports upper case\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bacc701-b213-48df-80fc-fb6225edaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transcriptions\n",
    "transcriptions_filename = \"/home/jeremy/htx_test1234/asr-train/cv-valid-dev.csv\"\n",
    "transcriptions = read_ref_csv(transcriptions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345b75c5-3d55-45df-a019-cb814e15de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 out of 4076 utterances found to contain hot-words\n"
     ]
    }
   ],
   "source": [
    "# Detect hot words\n",
    "hot_words = [\"be careful\", \"destroy\", \"stranger\"]\n",
    "utterances_with_hotwords = set()\n",
    "num_detected = 0\n",
    "for utt_name in sorted(transcriptions.keys()):\n",
    "    for w in hot_words:\n",
    "        if w.upper() in transcriptions[utt_name].upper():\n",
    "            utterances_with_hotwords.add(utt_name)\n",
    "            num_detected += 1\n",
    "            continue\n",
    "print(\"{} out of {} utterances found to contain hot-words\".format(num_detected, len(transcriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7230c7-502a-4b23-8cfa-036b1a48c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write detected utterances to file\n",
    "output_filename = \"/home/jeremy/htx_test1234/hotword-detection/detected.txt\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(list(sorted(utterances_with_hotwords)), file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
